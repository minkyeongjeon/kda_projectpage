<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean">
  <meta property="og:title" content="A pipeline for generating paired data for detoxifying implicit offensive language"/>
  <meta property="og:description" content="K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean"/>
  <meta property="og:url" content="https://github.com/minkyeongjeon/kda"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="/static/images/kda_pipeline.png" />
  <!-- <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->
  <meta property="og:image:width" content="2601"/>
  <meta property="og:image:height" content="1136"/>

  <meta name="twitter:title" content="K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean">
  <meta name="twitter:description" content="A pipeline for generating paired data for detoxifying implicit offensive language">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="/static/images/kda_pipeline.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Hate Speech, Synthetic Data, Implicit Offensive Language">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean</title>
  <link rel="icon" type="image/png" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sites.google.com/view/minjeon/home" target="_blank">Minkyeong Jeon<sup>1*</sup></a>,</span>
                <span class="author-block">
                  <a href="https://sites.google.com/view/hyemin-jeong" target="_blank">Hyemin Jeong<sup>2*</sup></a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=gmrtQV4AAAAJ&hl=en" target="_blank">Yerang Kim<sup>1</sup></a>,</span>
                <span class="author-block">
                  <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Jiyoung Kim<sup>3</sup></a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=v4A8cuUAAAAJ&hl=ko" target="_blank">Jae Hyeon Cho<sup>1</sup></a>,</span>
                <span class="author-block">
                  <a href="https://dmlab.korea.ac.kr/professor.html" target="_blank">Byung-Jun Lee<sup>1</sup></a>
                </span>
                </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Korea University&nbsp;&nbsp;
                      <sup>2</sup>Seoul National University&nbsp;&nbsp;
                      <sup>3</sup>KAIST AI
                    </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    <br>ACL 2025
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2506.13513" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/minkyeongjeon/kda_projectpage" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2506.13513" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                <!-- Huggingface Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/minkyeongjeon/kda-dataset" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="static/images/huggingface-color.svg" alt="Huggingface Logo">
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Your image here -->
      <img src="static/images/kda_pipeline.png" alt="K/DA teaser"/>
      <div class="content has-text-centered">
        <div class="is-size-6">
          An overview of K/DA, the pipeline for automated offensive language data generation.<br><br>
          <div style="text-align: left">
          <strong>Step 1</strong><br>Retrieve 9 semantically similar sentences from the community using cosine similarity. An LLM then synthesizes a toxic version by incorporating trend-aligned slang from these sentences.<br><br>
          <strong>Step 2</strong><br>An off-the-shelf LLM filters the candidates based on two criteria:<br>
          • <span style="font-size: 0.9em;"><strong>Pair consistency:</strong> How well the neutral-toxic pair shares the same content.</span><br>
          • <span style="font-size: 0.9em;"><strong>Implicit offensiveness:</strong> The toxic sentence should avoid being too explicitly offensive, while still containing a subtle or implicit form of toxicity.</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End teaser image -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <span style="color: red; font-style: italic; font-size: 0.9em">⚠️ Caution: This research includes content that may be considered offensive.</span><br>
            Language detoxification involves removing toxicity from offensive language. While a neutral-toxic paired dataset provides a straightforward approach for training detoxification models, creating such datasets presents several challenges: i) the need for human annotation to build paired data, and ii) the rapid evolution of offensive terms, rendering static datasets quickly outdated. To tackle these challenges, we introduce an automated paired data generation pipeline, called K/DA. This pipeline is designed to generate offensive language with implicit offensiveness and trend-aligned slang, making the resulting dataset suitable for detoxification model training. We demonstrate that the dataset generated by K/DA exhibits high pair consistency and greater implicit offensiveness compared to existing Korean datasets, and also demonstrates applicability to other languages. Furthermore, it enables effective training of a high-performing detoxification model with simple instruction fine-tuning. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Definition of Implicit Offensiveness -->
<section class="section teaser">
  <div class="hero-body">
    <div class="container">
      <div class="content">
        <div class="image-section">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Definition of Implicit Offensiveness</h2>
              <!-- Your image here -->
              <img src="static/images/community_category.png" alt="K/DA pipeline" style="max-width: 30%; height: auto; display: block; margin: 0 auto;"/>
              <div class="has-text-justified">
                <p>
                  <br><i><strong>Implicit offensiveness</strong></i> is a form of offensive language characterized by a tone of disregard or mockery that conveys derogatory meaning, such as <strong>sarcasm or social bias within context, while avoiding explicit expressions</strong>.
                  This figure illustrates the types of offensive comments collected from Korean online communities. These expressions are hard to capture without proper context. We divide the implicitly offensive comments into three subcategories:<br>
                  (1) disregard and mockery, consistent with past definitions of implicit offensiveness<br>
                  (2) community-specific slang that is familiar within certain groups but difficult for outsiders to interpret<br>
                  (3) variations of profanity used to avoid detection<br><br>
                  Specifically, communities with high-context languages such as Korean are more likely to use these types of implicit offensive expressions. Therefore, we use these categories to guide the data generation process. Furthermore, we demonstrate the <strong>language- and model- agnostic</strong> nature of this pipeline by generating data in English.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section teaser">
  <div class="hero-body">
    <div class="container">
      <div class="content">
        <div class="image-section">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Dataset Evaluation Results</h2>
              <!-- Your image here -->
              <img src="static/images/dataset_comp_kr.png" alt="Dataset comparison" style="max-width: 60%; height: auto; display: block; margin: 0 auto;"/>
              <div class="has-text-justified">
                <p>
                  <br>This table presents the G-Eval evaluations of the dataset generated from the K/DA pipeline compared to other Korean offensive language datasets. Using the proposed pipeline, we were able to create a paired dataset with greater implicit offensiveness and higher consistency between pairs. The tendency for overall offensiveness to be the lowest, while implicit offensiveness remains the highest, indicates that the dataset has been appropriately constructed, aligning with the definition of offensive language targeted in our paper.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section teaser">
  <div class="hero-body">
    <div class="container">
      <div class="content">
        <div class="image-section">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Instruction Tuning Results</h2>
              <!-- Your image here -->
              <img src="static/images/geval_it.png" alt="G-Eval results on instruction tuning" style="max-width: 60%; height: auto; display: block; margin: 0 auto;"/>
              <div class="has-text-justified">
                <p>
                  <br>This table presents the G-Eval results for detoxification. The goal is to achieve low offensiveness in the detoxified output. Along with reducing offensiveness, high consistency and fluency scores are essential, as a model could easily lower offensiveness by removing most of the potentially offensive content, but this would result in lower consistency and fluency scores.
                </p>
                <p>
                  The instruction-tuned detoxification model based on K/DA demonstrates improvements across all five criteria when tested on Ours and KOLD datasets. It is also evident that the superior detoxification performance achieved through instruction tuning on K/DA diminishes as we attempt to generalize further and disappears when tested in the most challenging transfer setting, BEEP. This decline is primarily due to the limited coverage of the neutral sentence from the dataset used, a limitation that can be easily addressed by diversifying the neutral sentence data.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section teaser">
  <div class="hero-body">
    <div class="container">
      <div class="content">
        <div class="image-section">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Human Evaluation Results</h2>
              <!-- Your image here -->
              <img src="static/images/humaneval_dataset_com.png" alt="Human evaluation dataset comparison" style="max-width: 30%; height: auto; display: block; margin: 0 auto;"/>
              <div class="has-text-justified">
                <p>
                  <br>Human evaluation result of 50 random samples from K/DA and K-OMG. The numbers in parentheses represent the Cronbach's α.
                  K/DA received higher scores for O and I, which are incorporated as O in K-OMG, reflecting offensive language more effectively in online communities. While K-OMG achieved a higher score for C, its Cronbach's α was relatively low, making it less reliable for direct comparison. Fluency was also rated higher in K-OMG; however, unlike K-OMG's evaluation instruction, which allowed evaluators to disregard grammatical errors, we did not include such a provision, leading to lower fluency scores in our evaluation.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section teaser">
  <div class="hero-body">
    <div class="container">
      <div class="content">
        <div class="image-section">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Detoxification Performance Comparison</h2>
              <!-- Your image here -->
              <img src="static/images/human_evaluation.png" alt="Human evaluation dataset comparison" style="max-width: 40%; height: auto; display: block; margin: 0 auto;"/>
              <div class="has-text-justified">
                <p>
                  <br>Human evaluation of detoxification performance tested on our model. It represents the percentage of preference for detoxified responses generated by our model, the model trained on another dataset (K-OMG, translated CADD), and cases where the performances are indistinguishable.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/watch?v=8mi8TYtiebU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video .-->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/ACL2025_poster_kda.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{jeon2025kdaautomateddatageneration,
      title={K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean}, 
      author={Minkyeong Jeon and Hyemin Jeong and Yerang Kim and Jiyoung Kim and Jae Hyeon Cho and Byung-Jun Lee},
      year={2025},
      eprint={2506.13513},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.13513}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
